# ğŸ›’ Pipeline ELT de E-commerce (Airflow + DuckDB)

![Status](https://img.shields.io/badge/Status-ConcluÃ­do-green) ![Python](https://img.shields.io/badge/Python-3.12-blue) ![Airflow](https://img.shields.io/badge/Apache%20Airflow-Docker-red)

Este repositÃ³rio contÃ©m o projeto final de Engenharia de Dados, demonstrando um pipeline **ELT (Extract, Load, Transform)** completo. O objetivo Ã© ingerir dados brutos de vendas, processÃ¡-los e gerar indicadores de negÃ³cio (KPIs) utilizando a **Arquitetura MedalhÃ£o** (Bronze, Silver, Gold).

---

## ğŸ›ï¸ Arquitetura do Projeto

O pipeline Ã© orquestrado pelo **Apache Airflow** rodando em containers Docker. O processamento de dados Ã© realizado utilizando **DuckDB** e **Python**, garantindo performance no tratamento de arquivos Parquet.

### Fluxo de Dados (Medallion Architecture):

1.  ğŸŸ¤ **Bronze (Raw):** IngestÃ£o do dado bruto (CSV) simulando um Data Lake.
2.  âšª **Silver (Clean):** Limpeza de dados, tipagem correta e deduplicaÃ§Ã£o. Salvo em Parquet.
3.  ğŸŸ¡ **Gold (Analytics):** AgregaÃ§Ã£o de dados para regras de negÃ³cio e cÃ¡lculo de KPIs.

---

## ğŸ› ï¸ Tecnologias Utilizadas

* **Linguagem:** Python 3.12
* **OrquestraÃ§Ã£o:** Apache Airflow 2.x
* **Processamento:** DuckDB & Pandas
* **Infraestrutura:** Docker & Docker Compose
* **Formato de Dados:** CSV (Input) e Parquet (Processado)

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```bash
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ ecommerce_elt.py       # DAG principal do Airflow (DefiniÃ§Ã£o do fluxo)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ raw_to_bronze.py       # Script de ingestÃ£o
â”‚   â”œâ”€â”€ bronze_to_silver.py    # Script de limpeza e transformaÃ§Ã£o
â”‚   â””â”€â”€ silver_to_gold.py      # Script de agregaÃ§Ã£o e KPIs
â”œâ”€â”€ data/                      # DiretÃ³rio local de dados (Ignorado no Git)
â”œâ”€â”€ logs/                      # Logs de execuÃ§Ã£o do Airflow
â”œâ”€â”€ docker-compose.yaml        # ConfiguraÃ§Ã£o dos containers e volumes
â”œâ”€â”€ requirements.txt           # Bibliotecas Python necessÃ¡rias
â””â”€â”€ visualizacao.py            # Script auxiliar para validaÃ§Ã£o final
```

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos
* Docker Desktop instalado e rodando.
* Git instalado.

### Passo a Passo

1.  **Clone o repositÃ³rio:**
    ```bash
    git clone [https://github.com/lucas-jmendes/projeto-elt-final.git](https://github.com/lucas-jmendes/projeto-elt-final.git)
    ```

2.  **Entre na pasta:**
    ```bash
    cd NOME_DO_REPO
    ```

3.  **Inicie o ambiente:**
    ```bash
    docker-compose up -d
    ```

4.  **Acesse a Interface do Airflow:**
    * Abra o navegador em: `http://localhost:8080`
    * Ative a DAG `ecommerce_elt` e clique em **Trigger DAG**.

5.  **Valide os Resultados:**
    ```bash
    python visualizacao.py
    ```

---

## ğŸ“Š KPIs Gerados (Camada Gold)

O pipeline entrega tabelas analÃ­ticas prontas para consumo de BI, contendo:

* **Faturamento Total:** Soma consolidada das vendas processadas.
* **Melhor Dia de Vendas:** IdentificaÃ§Ã£o da data com maior pico de faturamento.
* **Melhores Clientes:** Ranking de clientes com maior volume de compras.

---

## ğŸ‘¤ Autor

**Lucas Mendes**
Desenvolvido como parte da avaliaÃ§Ã£o final da disciplina de Engenharia de Dados.